{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "detect: \n 672a3182713fcdbb0a31b060eb98c50ec5096a2140e06662f2a364e235b3b008\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# make sure your aws role has the correct permissions to run textract, see https://docs.aws.amazon.com/textract/latest/dg/api-async-roles.html \n",
    "# to configure \n",
    "\n",
    "class ProcessType:\n",
    "    DETECTION = 1\n",
    "    ANALYSIS = 2    \n",
    "\n",
    "class DocumentProcessor:\n",
    "    jobId = ''\n",
    "    textract = boto3.client('textract')\n",
    "    sqs = boto3.client('sqs')\n",
    "    sns = boto3.client('sns')\n",
    "    roleArn = ''\n",
    "    bucket = ''\n",
    "    document = ''\n",
    "    sqsQueueUrl = ''\n",
    "    snsTopicArn = ''\n",
    "    processType = ''\n",
    "\n",
    "\n",
    "    def __init__(self, role, bucket, document,topic):\n",
    "        self.roleArn = role  #refers to roleARN, ours = 'arn:aws:iam::760515291717:role/TextractRole'\n",
    "        self.bucket = bucket\n",
    "        self.document = document  #refers to name of document being held in bucket\n",
    "        self.snsTopicArn = topic. #refers to snstopicARN, ours = 'arn:aws:sns:us-west-1:760515291717:nlp_topic'\n",
    "\n",
    "\n",
    "    def ProcessDocument(self,type):  #refers back to ProcessType class ^^\n",
    "        jobFound = False\n",
    "        self.processType=type\n",
    "        validType=False\n",
    "        \n",
    "        #Determine which type of processing to perform\n",
    "        if self.processType==ProcessType.DETECTION:\n",
    "            response = self.textract.start_document_text_detection(DocumentLocation={'S3Object': {'Bucket': self.bucket, 'Name': self.document}},\n",
    "            NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "\n",
    "            print('Processing type: Detection')\n",
    "            validType=True\n",
    "\n",
    "        if self.processType==ProcessType.ANALYSIS:\n",
    "            response = self.textract.start_document_analysis(DocumentLocation={'S3Object': {'Bucket': self.bucket, 'Name': self.document}},\n",
    "                FeatureTypes=[\"TABLES\", \"FORMS\"],\n",
    "                NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn':self.snsTopicArn})\n",
    "            \n",
    "            print('Processing type: Analysis')\n",
    "            validType=True\n",
    "        \n",
    "        if validType==False:\n",
    "            print(\"Invalid processing type. Choose Detection or Analysis.\")\n",
    "            return\n",
    "        print('Start Job Id: ' + response['JobId'])\n",
    "        dotLine=0\n",
    "        while jobFound == False:\n",
    "            sqsResponse = self.sqs.receive_message(QueueUrl=self.sqsQueueUrl,\n",
    "MessageAttributeNames=['ALL'],\n",
    "MaxNumberOfMessages=10)\n",
    "\n",
    "\n",
    "f_name = 'agapidou_2014'\n",
    "\n",
    "#have to set up an aws account s3 bucket... (cloud object storage)\n",
    "#for s3object, you need to specify bucket, name and version:\n",
    "s3_obj =  {\"Bucket\": 'bpdcnpdfbucket', \"Name\": 'agapidou_2014.pdf'}  #creating dictionary obj\n",
    "\n",
    "detect = client.start_document_text_detection(\n",
    "    DocumentLocation={'S3Object': s3_obj},\n",
    "    NotificationChannel={\n",
    "        'SNSTopicArn': 'arn:aws:sns:us-west-1:760515291717:nlp_topic',\n",
    "        'RoleArn': 'arn:aws:iam::760515291717:role/TextractRole'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3Bucket': 'bpdcnpdfbucket',\n",
    "        'S3Prefix': f_name\n",
    "    })  #for detecting and analyzing text in multipage docs (asynchronous op), I would try both syncrhonous and asynchronous, maybe the synchronous works for pdfs with just a couple of pages?\n",
    "\n",
    "print('detect job id: \\n', detect['JobId']) \n",
    "detect_jobid = detect['JobId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text = client.get_document_text_detection(\n",
    "    JobId = detect_jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'JobStatus': 'IN_PROGRESS', 'DetectDocumentTextModelVersion': '1.0', 'ResponseMetadata': {'RequestId': '249cc7f1-d9a5-407c-896a-3044749ee4d2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '249cc7f1-d9a5-407c-896a-3044749ee4d2', 'content-type': 'application/x-amz-json-1.1', 'content-length': '66', 'date': 'Tue, 27 Apr 2021 22:57:06 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}