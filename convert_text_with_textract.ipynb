{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 257)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m257\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# make sure your aws role has the correct permissions to run textract, see https://docs.aws.amazon.com/textract/latest/dg/api-async-roles.html \n",
    "# to configure \n",
    "\n",
    "class ProcessType:\n",
    "    DETECTION = 1\n",
    "    ANALYSIS = 2    \n",
    "\n",
    "class DocumentProcessor:\n",
    "    jobId = ''\n",
    "    textract = boto3.client('textract')\n",
    "    sqs = boto3.client('sqs')\n",
    "    sns = boto3.client('sns')\n",
    "    roleArn = ''\n",
    "    bucket = ''\n",
    "    document = ''\n",
    "    sqsQueueUrl = ''\n",
    "    snsTopicArn = ''\n",
    "    processType = ''\n",
    "\n",
    "\n",
    "    def __init__(self, role, bucket, document):\n",
    "\n",
    "        '''\n",
    "        Initiate 'DocumentProcessor' object with TextractRole, bucket, document in bucket, and nlp_topic\n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.roleArn = role  #refers to roleARN, ours = 'arn:aws:iam::760515291717:role/TextractRole'\n",
    "        self.bucket = bucket\n",
    "        self.document = document  #refers to name of document being held in bucket\n",
    "\n",
    "\n",
    "    def ProcessDocument(self,type):  #refers back to ProcessType class ^^\n",
    "\n",
    "        '''\n",
    "        Choose processing type: 1 = detection, 2 = analysis\n",
    "        Returns response of chosen process\n",
    "        \n",
    "        '''\n",
    "\n",
    "        jobFound = False\n",
    "        self.processType=type\n",
    "        validType=False\n",
    "        \n",
    "        #Determine which type of processing to perform\n",
    "        if self.processType==ProcessType.DETECTION:\n",
    "            response = self.textract.start_document_text_detection(DocumentLocation={'S3Object': {'Bucket': self.bucket, 'Name': self.document}},\n",
    "                NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn': self.snsTopicArn})\n",
    "\n",
    "            print('Processing type: Detection')\n",
    "            validType=True\n",
    "\n",
    "        if self.processType==ProcessType.ANALYSIS:\n",
    "            response = self.textract.start_document_analysis(DocumentLocation={'S3Object': {'Bucket': self.bucket, 'Name': self.document}},\n",
    "                FeatureTypes=[\"TABLES\"],\n",
    "                NotificationChannel={'RoleArn': self.roleArn, 'SNSTopicArn':self.snsTopicArn})\n",
    "            \n",
    "            print('Processing type: Analysis')\n",
    "            validType=True\n",
    "        \n",
    "        if validType==False:\n",
    "            print(\"Invalid processing type. Choose Detection or Analysis.\")\n",
    "            return\n",
    "\n",
    "        print('Start Job Id: ' + response['JobId'])\n",
    "        dotLine=0\n",
    "        \n",
    "        while jobFound == False:\n",
    "            sqsResponse = self.sqs.receive_message(QueueUrl=self.sqsQueueUrl, MessageAttributeNames=['ALL'], MaxNumberOfMessages=10)\n",
    "\n",
    "            if sqsResponse:\n",
    "                if 'Messages' not in sqsResponse:\n",
    "                    if dotLine<40:\n",
    "                        print('.', end='')\n",
    "                        dotLine=dotLine+1\n",
    "                    else:\n",
    "                        print()\n",
    "                        dotLine=0\n",
    "                    sys.stdout.flush()\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "\n",
    "                for message in sqsResponse['Messages']: \n",
    "                    notification = json.loads(message['Body'])\n",
    "                    textMessage = json.loads(notification['Message'])\n",
    "                    print(textMessage['JobId'])\n",
    "                    print(textMessage['Status'])\n",
    "\n",
    "                    if str(textMessage['JobId']) == response['JobId']:\n",
    "                        print('Matching Job Found:' + textMessage['JobId'])\n",
    "                        jobFound = True\n",
    "                        self.GetResults(textMessage['JobId'])\n",
    "                        self.sqs.delete_message(QueueUrl=self.sqsQueueUrl, ReceiptHandle=message['ReceiptHandle'])\n",
    "                    else:\n",
    "                        print(\"Job didn't match:\" + str(textMessage['JobId']) + ' : ' + str(response['JobId']))\n",
    "\n",
    "                    # delete the unknown message. consider sending to dead letter queue\n",
    "                    self.sqs.delete_message(QueueUrl=self.sqsQueueUrl, ReceiptHandle=message['ReceiptHandle'])\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "\n",
    "    def CreateTopicandQueue(self):\n",
    "        millis = str(int(round(time.time() * 1000)))\n",
    "        \n",
    "        #Create SNS topic\n",
    "        snsTopicName=\"AmazonTextractTopic\" + millis\n",
    "        topicResponse=self.sns.create_topic(Name=snsTopicName)\n",
    "        self.snsTopicArn = topicResponse['TopicArn']\n",
    "        \n",
    "        #create SQS queue\n",
    "        sqsQueueName=\"AmazonTextractQueue\" + millis\n",
    "        self.sqs.create_queue(QueueName=sqsQueueName)\n",
    "        self.sqsQueueUrl = self.sqs.get_queue_url(QueueName=sqsQueueName)['QueueUrl']\n",
    "        attribs = self.sqs.get_queue_attributes(QueueUrl=self.sqsQueueUrl, AttributeNames=['QueueArn'])['Attributes']\n",
    "        sqsQueueArn = attribs['QueueArn']\n",
    "        \n",
    "        # Subscribe SQS queue to SNS topic\n",
    "        self.sns.subscribe(\n",
    "            TopicArn=self.snsTopicArn,\n",
    "            Protocol='sqs',\n",
    "            Endpoint=sqsQueueArn)\n",
    "\n",
    "        #Authorize SNS to write SQS queue\n",
    "        policy = \"\"\"{{\"Version\":\"2012-10-17\", \"Statement\":[{{\n",
    "            \"Sid\":\"MyPolicy\",\n",
    "            \"Effect\":\"Allow\",\n",
    "            \"Principal\" : {{\"AWS\" : \"*\"}},\n",
    "            \"Action\":\"SQS:SendMessage\",\n",
    "            \"Resource\": \"{}\",\n",
    "            \"Condition\":{{\"ArnEquals\":{{\"aws:SourceArn\": \"{}\"}}\n",
    "            }} }}]}}\"\"\".format(sqsQueueArn, self.snsTopicArn)\n",
    "        \n",
    "        response = self.sqs.set_queue_attributes(\n",
    "            QueueUrl = self.sqsQueueUrl,\n",
    "            Attributes = {\n",
    "                'Policy' : policy\n",
    "            })\n",
    "\n",
    "\n",
    "    def DeleteTopicandQueue(self):\n",
    "        self.sqs.delete_queue(QueueUrl=self.sqsQueueUrl)\n",
    "        self.sns.delete_topic(TopicArn=self.snsTopicArn)\n",
    "\n",
    "\n",
    "\n",
    "    def DisplayBlockInfo(self,block):\n",
    "\n",
    "        '''\n",
    "        Display information about a block\n",
    "        '''\n",
    "\n",
    "        print (\"Block Id: \" + block['Id'])\n",
    "        print (\"Type: \" + block['BlockType'])\n",
    "        \n",
    "        if 'EntityTypes' in block:\n",
    "            print('EntityTypes: {}'.format(block['EntityTypes']))\n",
    "        \n",
    "        if 'Text' in block:\n",
    "            print(\"Text: \" + block['Text'])\n",
    "        \n",
    "        if block['BlockType'] != 'PAGE':\n",
    "            print(\"Confidence: \" + \"{:.2f}\".format(block['Confidence']) + \"%\")\n",
    "        \n",
    "        print('Page: {}'.format(block['Page']))\n",
    "        \n",
    "        if block['BlockType'] == 'CELL':\n",
    "            print('Cell Information')\n",
    "            print('\\tColumn: {} '.format(block['ColumnIndex']))\n",
    "            print('\\tRow: {}'.format(block['RowIndex']))\n",
    "            print('\\tColumn span: {} '.format(block['ColumnSpan']))\n",
    "            print('\\tRow span: {}'.format(block['RowSpan']))\n",
    "            if 'Relationships' in block:\n",
    "                print('\\tRelationships: {}'.format(block['Relationships']))\n",
    "        print('Geometry')\n",
    "        print('\\tBounding Box: {}'.format(block['Geometry']['BoundingBox']))\n",
    "        print('\\tPolygon: {}'.format(block['Geometry']['Polygon']))\n",
    "        \n",
    "        if block['BlockType'] == 'SELECTION_ELEMENT':\n",
    "            print('    Selection element detected: ', end='')\n",
    "            if block['SelectionStatus'] =='SELECTED':\n",
    "                print('Selected')\n",
    "            else:\n",
    "                print('Not selected')\n",
    "\n",
    "\n",
    "\n",
    "    def GetResults(self, jobId):\n",
    "       maxResults = 1000\n",
    "       paginationToken = None\n",
    "       finished = False\n",
    "       \n",
    "       while finished == False:\n",
    "           response=None\n",
    "           if self.processType==ProcessType.ANALYSIS:\n",
    "               if paginationToken==None:\n",
    "                   response = self.textract.get_document_analysis(JobId=jobId,\n",
    "                       MaxResults=maxResults)\n",
    "               else:\n",
    "                   response = self.textract.get_document_analysis(JobId=jobId,\n",
    "                       MaxResults=maxResults,\n",
    "                       NextToken=paginationToken)\n",
    "           \n",
    "           if self.processType==ProcessType.DETECTION:\n",
    "               if paginationToken==None:\n",
    "                   response = self.textract.get_document_text_detection(JobId=jobId, MaxResults=maxResults)\n",
    "               else:\n",
    "                   response = self.textract.get_document_text_detection(JobId=jobId, MaxResults=maxResults, NextToken=paginationToken)\n",
    "           \n",
    "           blocks=response['Blocks']\n",
    "           print ('Detected Document Text')\n",
    "           print ('Pages: {}'.format(response['DocumentMetadata']['Pages']))\n",
    "           \n",
    "           # Display block information\n",
    "           for block in blocks:\n",
    "                   self.DisplayBlockInfo(block)\n",
    "                   print()\n",
    "                   print()\n",
    "           if 'NextToken' in response:\n",
    "               paginationToken = response['NextToken']\n",
    "           else:\n",
    "               finished = True\n",
    "\n",
    "\n",
    "\n",
    "    def GetResultsDocumentAnalysis(self, jobId):\n",
    "       maxResults = 1000\n",
    "       paginationToken = None\n",
    "       finished = False\n",
    "       while finished == False:\n",
    "           response=None\n",
    "           if paginationToken==None:\n",
    "               response = self.textract.get_document_analysis(JobId=jobId,\n",
    "                                           MaxResults=maxResults)\n",
    "           else:\n",
    "               response = self.textract.get_document_analysis(JobId=jobId,\n",
    "                                           MaxResults=maxResults,\n",
    "                                           NextToken=paginationToken)\n",
    "           #Get the text blocks\n",
    "           blocks=response['Blocks']\n",
    "           print ('Analyzed Document Text')\n",
    "           print ('Pages: {}'.format(response['DocumentMetadata']['Pages']))\n",
    "           \n",
    "           # Display block information\n",
    "           for block in blocks:\n",
    "               self.DisplayBlockInfo(block)\n",
    "               print()\n",
    "               print()\n",
    "               \n",
    "               if 'NextToken' in response:\n",
    "                   paginationToken = response['NextToken']\n",
    "               else:\n",
    "                   finished = True\n",
    "\n",
    "    def main():\n",
    "        roleArn = ''\n",
    "        bucket = ''\n",
    "        document = ''\n",
    "\n",
    "        analyzer=DocumentProcessor(roleArn, bucket,document)\n",
    "        analyzer.CreateTopicandQueue()\n",
    "        analyzer.ProcessDocument(ProcessType.DETECTION)\n",
    "        analyzer.DeleteTopicandQueue()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = 'agapidou_2014'\n",
    "\n",
    "#have to set up an aws account s3 bucket... (cloud object storage)\n",
    "#for s3object, you need to specify bucket, name and version:\n",
    "s3_obj =  {\"Bucket\": 'bpdcnpdfbucket', \"Name\": 'agapidou_2014.pdf'}  #creating dictionary obj\n",
    "\n",
    "detect = client.start_document_text_detection(\n",
    "    DocumentLocation={'S3Object': s3_obj},\n",
    "    NotificationChannel={\n",
    "        'SNSTopicArn': 'arn:aws:sns:us-west-1:760515291717:nlp_topic',\n",
    "        'RoleArn': 'arn:aws:iam::760515291717:role/TextractRole'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3Bucket': 'bpdcnpdfbucket',\n",
    "        'S3Prefix': f_name\n",
    "    })  #for detecting and analyzing text in multipage docs (asynchronous op), I would try both syncrhonous and asynchronous, maybe the synchronous works for pdfs with just a couple of pages?\n",
    "\n",
    "print('detect job id: \\n', detect['JobId']) \n",
    "detect_jobid = detect['JobId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text = client.get_document_text_detection(\n",
    "    JobId = detect_jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'JobStatus': 'IN_PROGRESS', 'DetectDocumentTextModelVersion': '1.0', 'ResponseMetadata': {'RequestId': '249cc7f1-d9a5-407c-896a-3044749ee4d2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '249cc7f1-d9a5-407c-896a-3044749ee4d2', 'content-type': 'application/x-amz-json-1.1', 'content-length': '66', 'date': 'Tue, 27 Apr 2021 22:57:06 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}